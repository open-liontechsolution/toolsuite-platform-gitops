# CloudNativePG (CNPG) - Postgres GitOps Base

This directory provides the **base** manifests for installing the CNPG operator and a highly available Postgres cluster. It is designed to be consumed by Argo CD as a Kustomize application, with environment-specific overlays under `clusters/`.

## What this base includes

- CNPG operator installation (remote manifest pinned to `v1.22.0`).
- A 3-instance Postgres cluster (`platform-postgres`) in the `data-system` namespace.
- Anti-affinity to spread replicas across nodes.
- Node **preference** for `workload=db` nodes using node affinity.
- Logical backup CronJob writing to a PVC.
- SealedSecret placeholder for application credentials (`platform-postgres-app`).

## Argo CD usage

Point an Argo CD Application at one of the environment overlays. The repository now supports multiple environments in both local and cloud deployments:

**Local environments (k3s + Longhorn):**
- `clusters/local/dev` - Development (1 instance, minimal resources)
- `clusters/local/qa` - QA (2 instances, moderate resources)
- `clusters/local/prod` - Production (3 instances, high resources)

**Cloud environments (EKS/GKE/AKS):**
- `clusters/cloud/dev` - Development (2 instances)
- `clusters/cloud/qa` - QA (2 instances, increased resources)
- `clusters/cloud/prod` - Production (3 instances, HA setup)

Example Argo CD Application:

> **Note:** Replace `<org>` with your GitHub organization or username in the `repoURL` below.

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: data-cnpg-dev
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/<org>/toolsuite-platform-gitops
    path: clusters/local/dev  # Change to local/qa, local/prod, cloud/dev, etc.
    targetRevision: main
  destination:
    server: https://kubernetes.default.svc
    namespace: data-system
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
```

## Verification

After Argo CD sync or manual deployment:

```bash
# Check CNPG operator (common to all environments)
kubectl get pods -n cnpg-system

# Check your specific environment (replace data-dev with your namespace)
kubectl get pods -n data-dev
kubectl get cluster -n data-dev
kubectl get services -n data-dev | grep platform-postgres
kubectl get cronjob -n data-dev
kubectl get pvc -n data-dev
```

> **Note:** The `cnpg-system` namespace is automatically created by the CNPG operator manifest. Each environment creates its own namespace (`data-dev`, `data-qa`, or `data-prod`) through Kustomize transformation.

CNPG automatically creates services:

- `platform-postgres-rw` (read/write primary)
- `platform-postgres-ro` (read-only)

## Credentials strategy

- **Superuser** credentials are generated by CNPG and stored in the secret:
  - `platform-postgres-superuser` (auto-created by the operator).
- **Application** credentials must be created manually using one of these approaches:

### Option 1: Using Sealed Secrets (Recommended for GitOps)

1. Create a plain secret based on the example:
   ```bash
   cp apps/data/cnpg/secret-app.example.yaml apps/data/cnpg/secret-app.yaml
   # Edit secret-app.yaml and set a strong password
   ```

2. Encrypt it with kubeseal:
   ```bash
   kubeseal --format=yaml \
     < apps/data/cnpg/secret-app.yaml \
     > apps/data/cnpg/sealedsecret-app.yaml
   ```

3. Add the sealed secret to your environment's kustomization:
   ```yaml
   # In clusters/local/dev/kustomization.yaml (or your target environment)
   resources:
     - ../../../apps/data/cnpg
     - ../../../apps/data/cnpg/sealedsecret-app.yaml
   ```

4. Delete the plain secret file:
   ```bash
   rm apps/data/cnpg/secret-app.yaml
   ```

### Option 2: Using Plain Secrets (Development only)

For local development, you can apply the secret directly:
```bash
kubectl apply -f apps/data/cnpg/secret-app.example.yaml
```

> **Security Note:** Never commit plain secrets to Git. Use Sealed Secrets, external secret managers (e.g., External Secrets Operator), or apply secrets manually.

### Example Files Provided

- `secret-app.example.yaml` - Plain secret template (use this to create your secret)
- `sealedsecret-app.example.yaml` - Sealed secret template (reference for structure)

## Backups

A logical backup CronJob runs nightly and stores dumps in the PVC `platform-postgres-backups`.

### Restore procedure

1. Identify the backup file in the PVC (replace `data-dev` with your namespace):
   ```bash
   kubectl exec -n data-dev platform-postgres-1 -- ls -lh /backups
   ```
2. Copy the file locally (optional):
   ```bash
   kubectl cp data-dev/<backup-pod>:/backups/cluster-<timestamp>.sql ./cluster.sql
   ```
3. Restore into the primary:
   ```bash
   kubectl exec -n data-dev -it <primary-pod> -- psql -U postgres -f /backups/cluster-<timestamp>.sql
   ```

> Tip: you can also attach the backup PVC to a temporary job or pod for inspection.
